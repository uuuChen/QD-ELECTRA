{
    "seed": 3333,
    "batch_size": 10,
    "lr": 5e-4,
    "n_epochs": 100,
    "warmup": 0.1,
    "save_steps": 10000,
    "total_steps": 1000000,
    "temperature": 1,
    "lambda_": 50,
    "soft_logits_factor": 100,
    "atten_layers_factor": 70
}